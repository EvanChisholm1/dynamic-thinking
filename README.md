# dynamic thinking

why do neural networks use the same compute for every forward pass? shouldn't some problems require more compute than others? I think this is particularly true for language models, where the amount of computation required to understand a sentence can vary greatly. I'm interested in exploring how to dynamically change the amount of computation in a neural network.

a research project on dynamically changing the amount of computation in a neural network.
