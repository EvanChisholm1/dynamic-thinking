{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard gpt modules + model definition\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    block_size: int\n",
    "    vocab_size: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embd: int\n",
    "    dropout: float\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(config.n_embd, config.n_embd * 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(config.n_embd * 4, config.n_embd)\n",
    "    \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(config.n_embd, config.n_embd * 3)\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.redidual_dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config.block_size, config.block_size)).view(1, 1, config.block_size, config.block_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        q, k, v = self.attn(x).chunk(3, dim=2)\n",
    "        q = q.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(1, 2)\n",
    "        k = k.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(1, 2)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) * (k.size(-1) ** (-1/2))\n",
    "        att = att.masked_fill(self.tril[:, :, :T, :T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_dropout(att)\n",
    "        att = att @ v\n",
    "\n",
    "        y = att.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        y = self.redidual_dropout(self.proj(y))\n",
    "        return y\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "\n",
    "        self.sa = SelfAttention(config)\n",
    "        self.mlp = MLP(config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class Embed(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.te = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.pe = nn.Embedding(config.block_size, config.n_embd)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        T = x.size(1)\n",
    "        pos = torch.arange(T, device=x.device).unsqueeze(0)\n",
    "        return self.dropout(self.te(x) + self.pe(pos))\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = Embed(config)\n",
    "\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"params:\", self.get_param_count())\n",
    "    \n",
    "    def get_param_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        x = self.embed(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), ignore_index=-1)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (torch.randn(1, 10) * 2 > 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Looper(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.L = nn.Parameter(torch.tensor(1.5))\n",
    "\n",
    "        self.layer = layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lower = torch.floor(self.L)\n",
    "\n",
    "        for _ in range(int(lower)):\n",
    "            x = self.layer(x)\n",
    "        \n",
    "        x = x * (1 - (self.L - lower)) + self.layer(x) * (self.L - lower)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MLP1Output(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(config.n_embd, config.n_embd * 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(config.n_embd * 2, 1)\n",
    "    \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LooperCalculator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "\n",
    "        # self.sa = SelfAttention(config)\n",
    "        self.mlp = MLP1Output(config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "class DynamicLooper(nn.Module):\n",
    "    def __init__(self, config,  layer, max_NL=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.loop_calculator = LooperCalculator(config)\n",
    "        self.max_NL = max_NL\n",
    "\n",
    "        self.layer = layer\n",
    "\n",
    "        self.avg_loop = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ls = F.sigmoid(self.loop_calculator(x)) * self.max_NL\n",
    "\n",
    "        max_L = torch.max(ls).ceil()\n",
    "\n",
    "        for i in range(int(max_L)):\n",
    "            multipliers = (ls > i).float()\n",
    "\n",
    "            x = (x * (1 - multipliers)) + self.layer(x) * multipliers\n",
    "        \n",
    "        fractional = ls - torch.floor(ls)\n",
    "\n",
    "        x = x * (1 - fractional) + self.layer(x) * fractional\n",
    "\n",
    "        self.avg_loop = 0.9 * self.avg_loop + 0.1 * ls.mean().item()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTLooper(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = Embed(config)\n",
    "\n",
    "        self.blocks = nn.ModuleList([Looper(Block(config)) for _ in range(config.n_layer)])\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"params:\", self.get_param_count())\n",
    "    \n",
    "    def get_param_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        x = self.embed(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), ignore_index=-1)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "class DynamicGPTLooper(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = Embed(config)\n",
    "\n",
    "        self.blocks = nn.ModuleList([DynamicLooper(config, Block(config)) for _ in range(config.n_layer)])\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"params:\", self.get_param_count())\n",
    "    \n",
    "    def get_param_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        x = self.embed(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), ignore_index=-1)\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the basic idea of the offramp is to have an LM head and accuracy predictor at every block\n",
    "# if the accuracy predictor is good enough, we can stop the model early\n",
    "\n",
    "class OffRamp(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = Block(config)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.acc_predictor = MLP1Output(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        logits = self.lm_head(x)\n",
    "        acc = self.acc_predictor(x)\n",
    "        return x, logits, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "data = torch.tensor(encode(text), dtype=torch.long, device=device)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: 1911298\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "block_size = 128 \n",
    "n_layer = 2\n",
    "n_head = 8 \n",
    "n_embd = 256\n",
    "\n",
    "config = Config(block_size=block_size, vocab_size=vocab_size, n_layer=n_layer, n_head=n_head, n_embd=n_embd, dropout=0.1)\n",
    "model = DynamicGPTLooper(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data= train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(eval_iters=10):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, base_lr=3e-4, l_lr=1e-3):\n",
    "    l_params = [param for name, param in model.named_parameters() if 'layer' in name]\n",
    "    other_params = [param for name, param in model.named_parameters() if 'layer' not in name]\n",
    "\n",
    "    param_groups = [\n",
    "        {'params': l_params, 'lr': l_lr},\n",
    "        {'params': other_params, 'lr': base_lr}\n",
    "    ]\n",
    "\n",
    "    optimizer = torch.optim.Adam(param_groups)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "# optimizer = get_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter():\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lossi.append(loss.item())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7980ff7869b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 4.376579284667969\n",
      "\n",
      "train loss: 3.741128921508789, val loss: 3.7579619884490967\n",
      "\n",
      "avg L values:\n",
      "3.778711109147348\n",
      "3.956132146916308\n",
      "iter: 100, loss: 2.506061315536499\n",
      "iter: 200, loss: 2.457000732421875\n",
      "iter: 300, loss: 2.3629355430603027\n",
      "iter: 400, loss: 2.222033739089966\n",
      "iter: 500, loss: 2.067612886428833\n",
      "iter: 600, loss: 2.0530452728271484\n",
      "iter: 700, loss: 1.984039545059204\n",
      "iter: 800, loss: 1.9191969633102417\n",
      "iter: 900, loss: 1.7928987741470337\n",
      "iter: 1000, loss: 1.835871696472168\n",
      "\n",
      "train loss: 1.7594120502471924, val loss: 1.8910787105560303\n",
      "\n",
      "avg L values:\n",
      "8.894811970049131\n",
      "7.351494202720192\n",
      "iter: 1100, loss: 1.8011078834533691\n",
      "iter: 1200, loss: 1.7065879106521606\n",
      "iter: 1300, loss: 1.7208906412124634\n",
      "iter: 1400, loss: 1.656312346458435\n",
      "iter: 1500, loss: 1.6101208925247192\n",
      "iter: 1600, loss: 1.6068496704101562\n",
      "iter: 1700, loss: 1.622718095779419\n",
      "iter: 1800, loss: 1.64304518699646\n",
      "iter: 1900, loss: 1.6130995750427246\n",
      "iter: 2000, loss: 1.521501898765564\n",
      "\n",
      "train loss: 1.5113636255264282, val loss: 1.7150733470916748\n",
      "\n",
      "avg L values:\n",
      "9.386062050002325\n",
      "7.6402579885142625\n",
      "iter: 2100, loss: 1.595815658569336\n",
      "iter: 2200, loss: 1.5926997661590576\n",
      "iter: 2300, loss: 1.5391098260879517\n",
      "iter: 2400, loss: 1.5070897340774536\n",
      "iter: 2500, loss: 1.419121265411377\n",
      "iter: 2600, loss: 1.4502769708633423\n",
      "iter: 2700, loss: 1.555547833442688\n",
      "iter: 2800, loss: 1.51065993309021\n",
      "iter: 2900, loss: 1.4736024141311646\n",
      "iter: 3000, loss: 1.4738086462020874\n",
      "\n",
      "train loss: 1.4145201444625854, val loss: 1.646442174911499\n",
      "\n",
      "avg L values:\n",
      "9.541611864191431\n",
      "7.852644029486425\n",
      "iter: 3100, loss: 1.4507389068603516\n",
      "iter: 3200, loss: 1.3907556533813477\n",
      "iter: 3300, loss: 1.453222632408142\n",
      "iter: 3400, loss: 1.4144054651260376\n",
      "iter: 3500, loss: 1.4531370401382446\n",
      "iter: 3600, loss: 1.3822518587112427\n",
      "iter: 3700, loss: 1.4658160209655762\n",
      "iter: 3800, loss: 1.3930068016052246\n",
      "iter: 3900, loss: 1.4509367942810059\n",
      "iter: 4000, loss: 1.3889131546020508\n",
      "\n",
      "train loss: 1.3512073755264282, val loss: 1.560409665107727\n",
      "\n",
      "avg L values:\n",
      "9.724987111571965\n",
      "7.7272376892112105\n",
      "iter: 4100, loss: 1.3855046033859253\n",
      "iter: 4200, loss: 1.4321082830429077\n",
      "iter: 4300, loss: 1.3626279830932617\n",
      "iter: 4400, loss: 1.4011037349700928\n",
      "iter: 4500, loss: 1.3420377969741821\n",
      "iter: 4600, loss: 1.3244247436523438\n",
      "iter: 4700, loss: 1.3798426389694214\n",
      "iter: 4800, loss: 1.3680557012557983\n",
      "iter: 4900, loss: 1.4049910306930542\n",
      "iter: 5000, loss: 1.3360071182250977\n",
      "\n",
      "train loss: 1.3027105331420898, val loss: 1.5604273080825806\n",
      "\n",
      "avg L values:\n",
      "9.781766955205514\n",
      "7.715765658639104\n",
      "iter: 5100, loss: 1.3913415670394897\n",
      "iter: 5200, loss: 1.3956072330474854\n",
      "iter: 5300, loss: 1.3806335926055908\n",
      "iter: 5400, loss: 1.3504929542541504\n",
      "iter: 5500, loss: 1.3602697849273682\n",
      "iter: 5600, loss: 1.3451666831970215\n",
      "iter: 5700, loss: 1.3257533311843872\n",
      "iter: 5800, loss: 1.3185468912124634\n",
      "iter: 5900, loss: 1.3555833101272583\n",
      "iter: 6000, loss: 1.2838717699050903\n",
      "\n",
      "train loss: 1.2761443853378296, val loss: 1.5123172998428345\n",
      "\n",
      "avg L values:\n",
      "9.778349514747202\n",
      "7.817504145408487\n",
      "iter: 6100, loss: 1.3421176671981812\n",
      "iter: 6200, loss: 1.314042568206787\n",
      "iter: 6300, loss: 1.2744905948638916\n",
      "iter: 6400, loss: 1.3251363039016724\n",
      "iter: 6500, loss: 1.3035393953323364\n",
      "iter: 6600, loss: 1.315388560295105\n",
      "iter: 6700, loss: 1.294304609298706\n",
      "iter: 6800, loss: 1.3319647312164307\n",
      "iter: 6900, loss: 1.3317118883132935\n",
      "iter: 7000, loss: 1.250849723815918\n",
      "\n",
      "train loss: 1.2529376745224, val loss: 1.534690260887146\n",
      "\n",
      "avg L values:\n",
      "9.838532005590377\n",
      "7.744953376930687\n",
      "iter: 7100, loss: 1.26992928981781\n",
      "iter: 7200, loss: 1.3085960149765015\n",
      "iter: 7300, loss: 1.2465145587921143\n",
      "iter: 7400, loss: 1.2753592729568481\n",
      "iter: 7500, loss: 1.308213233947754\n",
      "iter: 7600, loss: 1.2861697673797607\n",
      "iter: 7700, loss: 1.222100019454956\n",
      "iter: 7800, loss: 1.242274522781372\n",
      "iter: 7900, loss: 1.2466237545013428\n",
      "iter: 8000, loss: 1.2518811225891113\n",
      "\n",
      "train loss: 1.2185477018356323, val loss: 1.521162748336792\n",
      "\n",
      "avg L values:\n",
      "9.833328333938763\n",
      "7.692347746103225\n",
      "iter: 8100, loss: 1.2865917682647705\n",
      "iter: 8200, loss: 1.2942652702331543\n",
      "iter: 8300, loss: 1.3055635690689087\n",
      "iter: 8400, loss: 1.2463431358337402\n",
      "iter: 8500, loss: 1.2470186948776245\n",
      "iter: 8600, loss: 1.2245861291885376\n",
      "iter: 8700, loss: 1.259838581085205\n",
      "iter: 8800, loss: 1.251806378364563\n",
      "iter: 8900, loss: 1.237246036529541\n",
      "iter: 9000, loss: 1.2561222314834595\n",
      "\n",
      "train loss: 1.1866389513015747, val loss: 1.5047873258590698\n",
      "\n",
      "avg L values:\n",
      "9.836411097576294\n",
      "7.775962105865796\n",
      "iter: 9100, loss: 1.2561835050582886\n",
      "iter: 9200, loss: 1.2605478763580322\n",
      "iter: 9300, loss: 1.2153786420822144\n",
      "iter: 9400, loss: 1.2303543090820312\n",
      "iter: 9500, loss: 1.2310044765472412\n",
      "iter: 9600, loss: 1.2248646020889282\n",
      "iter: 9700, loss: 1.2268038988113403\n",
      "iter: 9800, loss: 1.217363715171814\n",
      "iter: 9900, loss: 1.2246507406234741\n",
      "iter: 10000, loss: 1.2326661348342896\n",
      "\n",
      "train loss: 1.1637521982192993, val loss: 1.5171223878860474\n",
      "\n",
      "avg L values:\n",
      "9.84224291458408\n",
      "7.681170229009431\n"
     ]
    }
   ],
   "source": [
    "for i in range(10001):\n",
    "    loss = iter()\n",
    "    lossi.append(loss.item())\n",
    "    if i % 100 == 0:\n",
    "        print(f\"iter: {i}, loss: {loss.item()}\")\n",
    "    if i % 1000 == 0:\n",
    "        print()\n",
    "        losses = estimate_loss()\n",
    "        print(f\"train loss: {losses['train']}, val loss: {losses['val']}\")\n",
    "        print()\n",
    "\n",
    "        train_losses.append(losses['train'])\n",
    "        test_losses.append(losses['val'])\n",
    "\n",
    "        print(\"avg L values:\")\n",
    "        for layer in model.blocks:\n",
    "            print(layer.avg_loop)\n",
    "\n",
    "        # print(\"L values:\")\n",
    "        # for layer in model.blocks:\n",
    "        #     print(layer.L.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]], device='cuda:0')\n",
      "\n",
      "Have I topforce him, he had something eyes or away:\n",
      "'Tis Lord Rivery, and your seems were for the corse;\n",
      "Richard I woo the grace, or stay to study,\n",
      "Neglecting his is another fire.\n",
      "\n",
      "LADY ANNE:\n",
      "Nay, no, thou know'st follow'st\n",
      "Me all their eyes, madam, tire a\n"
     ]
    }
   ],
   "source": [
    "def generate(max_new=256):\n",
    "    model.eval()\n",
    "    idx = torch.tensor(encode(\"\\n\"), dtype=torch.long, device=device).unsqueeze(0)\n",
    "    print(idx)\n",
    "    for _ in range(max_new):\n",
    "        idx_cond = idx[:, -block_size:]\n",
    "        logits, loss = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    # decode and print\n",
    "    out = idx.squeeze().tolist()\n",
    "    out = decode(out)\n",
    "\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "print(generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7981c024edd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('losses')\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='val')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
