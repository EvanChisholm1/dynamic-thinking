{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard gpt modules + model definition\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    block_size: int\n",
    "    vocab_size: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embd: int\n",
    "    dropout: float\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(config.n_embd, config.n_embd * 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(config.n_embd * 4, config.n_embd)\n",
    "    \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(config.n_embd, config.n_embd * 3)\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.redidual_dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config.block_size, config.block_size)).view(1, 1, config.block_size, config.block_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        q, k, v = self.attn(x).chunk(3, dim=2)\n",
    "        q = q.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(1, 2)\n",
    "        k = k.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(1, 2)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) * (k.size(-1) ** (-1/2))\n",
    "        att = att.masked_fill(self.tril[:, :, :T, :T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_dropout(att)\n",
    "        att = att @ v\n",
    "\n",
    "        y = att.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        y = self.redidual_dropout(self.proj(y))\n",
    "        return y\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "\n",
    "        self.sa = SelfAttention(config)\n",
    "        self.mlp = MLP(config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class Embed(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.te = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.pe = nn.Embedding(config.block_size, config.n_embd)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        T = x.size(1)\n",
    "        pos = torch.arange(T, device=x.device).unsqueeze(0)\n",
    "        return self.dropout(self.te(x) + self.pe(pos))\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = Embed(config)\n",
    "\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"params:\", self.get_param_count())\n",
    "    \n",
    "    def get_param_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        x = self.embed(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), ignore_index=-1)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (torch.randn(1, 10) * 2 > 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Looper(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.L = nn.Parameter(torch.tensor(1.5))\n",
    "\n",
    "        self.layer = layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lower = torch.floor(self.L)\n",
    "\n",
    "        for _ in range(int(lower)):\n",
    "            x = self.layer(x)\n",
    "        \n",
    "        x = x * (1 - (self.L - lower)) + self.layer(x) * (self.L - lower)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MLP1Output(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(config.n_embd, config.n_embd * 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(config.n_embd * 2, 1)\n",
    "    \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LooperCalculator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "\n",
    "        self.sa = SelfAttention(config)\n",
    "        self.mlp = MLP1Output(config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "class DynamicLooper(nn.Module):\n",
    "    def __init__(self, config,  layer, max_NL=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.loop_calculator = Block(config)\n",
    "        self.max_NL = max_NL\n",
    "\n",
    "        self.layer = layer\n",
    "\n",
    "        self.avg_loop = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ls = F.sigmoid(self.loop_calculator(x)) * self.max_NL\n",
    "\n",
    "        max_L = torch.max(ls).ceil()\n",
    "\n",
    "        for i in range(int(max_L)):\n",
    "            multipliers = (ls > i).float()\n",
    "\n",
    "            x = (x * (1 - multipliers)) + self.layer(x) * multipliers\n",
    "        \n",
    "        fractional = ls - torch.floor(ls)\n",
    "\n",
    "        x = x * (1 - fractional) + self.layer(x) * fractional\n",
    "\n",
    "        self.avg_loop = 0.9 * self.avg_loop + 0.1 * ls.mean().item()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTLooper(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = Embed(config)\n",
    "\n",
    "        self.blocks = nn.ModuleList([Looper(Block(config)) for _ in range(config.n_layer)])\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"params:\", self.get_param_count())\n",
    "    \n",
    "    def get_param_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        x = self.embed(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), ignore_index=-1)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "class DynamicGPTLooper(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = Embed(config)\n",
    "\n",
    "        self.blocks = nn.ModuleList([DynamicLooper(config, Block(config)) for _ in range(config.n_layer)])\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"params:\", self.get_param_count())\n",
    "    \n",
    "    def get_param_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        x = self.embed(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), ignore_index=-1)\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the basic idea of the offramp is to have an LM head and accuracy predictor at every block\n",
    "# if the accuracy predictor is good enough, we can stop the model early\n",
    "\n",
    "class OffRamp(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = Block(config)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.acc_predictor = MLP1Output(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        logits = self.lm_head(x)\n",
    "        acc = self.acc_predictor(x)\n",
    "        return x, logits, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "data = torch.tensor(encode(text), dtype=torch.long, device=device)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: 3225600\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "block_size = 128 \n",
    "n_layer = 2\n",
    "n_head = 8 \n",
    "n_embd = 256\n",
    "\n",
    "config = Config(block_size=block_size, vocab_size=vocab_size, n_layer=n_layer, n_head=n_head, n_embd=n_embd, dropout=0.1)\n",
    "model = DynamicGPTLooper(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data= train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(eval_iters=10):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, base_lr=3e-4, l_lr=1e-3):\n",
    "    l_params = [param for name, param in model.named_parameters() if 'layer' in name]\n",
    "    other_params = [param for name, param in model.named_parameters() if 'layer' not in name]\n",
    "\n",
    "    param_groups = [\n",
    "        {'params': l_params, 'lr': l_lr},\n",
    "        {'params': other_params, 'lr': base_lr}\n",
    "    ]\n",
    "\n",
    "    optimizer = torch.optim.Adam(param_groups)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "# optimizer = get_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter():\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lossi.append(loss.item())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f31be3bf040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 4.4415788650512695\n",
      "\n",
      "train loss: 3.7872462272644043, val loss: 3.8145980834960938\n",
      "\n",
      "avg L values:\n",
      "4.4341209209990495\n",
      "4.027368718116302\n",
      "iter: 100, loss: 2.548718214035034\n",
      "iter: 200, loss: 2.4274096488952637\n",
      "iter: 300, loss: 2.3076932430267334\n",
      "iter: 400, loss: 2.1999266147613525\n",
      "iter: 500, loss: 2.1222760677337646\n",
      "iter: 600, loss: 2.012693166732788\n",
      "iter: 700, loss: 1.8985097408294678\n",
      "iter: 800, loss: 1.8966736793518066\n",
      "iter: 900, loss: 1.851154088973999\n",
      "iter: 1000, loss: 1.7216827869415283\n",
      "\n",
      "train loss: 1.7363102436065674, val loss: 1.8778549432754517\n",
      "\n",
      "avg L values:\n",
      "6.5191471194091815\n",
      "6.231697889165663\n",
      "iter: 1100, loss: 1.7758798599243164\n",
      "iter: 1200, loss: 1.7532345056533813\n",
      "iter: 1300, loss: 1.7457566261291504\n",
      "iter: 1400, loss: 1.6406198740005493\n",
      "iter: 1500, loss: 1.5596801042556763\n",
      "iter: 1600, loss: 1.615716814994812\n",
      "iter: 1700, loss: 1.582979440689087\n",
      "iter: 1800, loss: 1.6195865869522095\n",
      "iter: 1900, loss: 1.5613229274749756\n",
      "iter: 2000, loss: 1.5223931074142456\n",
      "\n",
      "train loss: 1.514357566833496, val loss: 1.6685121059417725\n",
      "\n",
      "avg L values:\n",
      "6.920966022205657\n",
      "6.350688719848673\n",
      "iter: 2100, loss: 1.516247272491455\n",
      "iter: 2200, loss: 1.4946746826171875\n",
      "iter: 2300, loss: 1.4985711574554443\n",
      "iter: 2400, loss: 1.47382652759552\n",
      "iter: 2500, loss: 1.4700191020965576\n",
      "iter: 2600, loss: 1.4844233989715576\n",
      "iter: 2700, loss: 1.4925358295440674\n",
      "iter: 2800, loss: 1.4531879425048828\n",
      "iter: 2900, loss: 1.460275411605835\n",
      "iter: 3000, loss: 1.4483017921447754\n",
      "\n",
      "train loss: 1.4167916774749756, val loss: 1.602638602256775\n",
      "\n",
      "avg L values:\n",
      "7.0524911341094505\n",
      "6.540510393912458\n",
      "iter: 3100, loss: 1.477097511291504\n",
      "iter: 3200, loss: 1.4306750297546387\n",
      "iter: 3300, loss: 1.4687964916229248\n",
      "iter: 3400, loss: 1.4454059600830078\n",
      "iter: 3500, loss: 1.3553972244262695\n",
      "iter: 3600, loss: 1.4165633916854858\n",
      "iter: 3700, loss: 1.4131226539611816\n",
      "iter: 3800, loss: 1.4167228937149048\n",
      "iter: 3900, loss: 1.401236891746521\n",
      "iter: 4000, loss: 1.3810738325119019\n",
      "\n",
      "train loss: 1.3485609292984009, val loss: 1.5888879299163818\n",
      "\n",
      "avg L values:\n",
      "7.2049886882605545\n",
      "6.644106124806765\n",
      "iter: 4100, loss: 1.3004543781280518\n",
      "iter: 4200, loss: 1.372010350227356\n",
      "iter: 4300, loss: 1.3671141862869263\n",
      "iter: 4400, loss: 1.3854613304138184\n",
      "iter: 4500, loss: 1.4034875631332397\n",
      "iter: 4600, loss: 1.3510890007019043\n",
      "iter: 4700, loss: 1.3203587532043457\n",
      "iter: 4800, loss: 1.3561344146728516\n",
      "iter: 4900, loss: 1.3448656797409058\n",
      "iter: 5000, loss: 1.3715038299560547\n",
      "\n",
      "train loss: 1.2858047485351562, val loss: 1.5447425842285156\n",
      "\n",
      "avg L values:\n",
      "7.2570191487457025\n",
      "6.650671471914457\n",
      "iter: 5100, loss: 1.3276954889297485\n",
      "iter: 5200, loss: 1.2806005477905273\n",
      "iter: 5300, loss: 1.3499842882156372\n",
      "iter: 5400, loss: 1.3466705083847046\n",
      "iter: 5500, loss: 1.354819655418396\n",
      "iter: 5600, loss: 1.3751519918441772\n",
      "iter: 5700, loss: 1.3363875150680542\n",
      "iter: 5800, loss: 1.321459174156189\n",
      "iter: 5900, loss: 1.293975591659546\n",
      "iter: 6000, loss: 1.35934317111969\n",
      "\n",
      "train loss: 1.2514641284942627, val loss: 1.542799711227417\n",
      "\n",
      "avg L values:\n",
      "7.329369244368724\n",
      "6.6337671027373615\n",
      "iter: 6100, loss: 1.2951704263687134\n",
      "iter: 6200, loss: 1.2599152326583862\n",
      "iter: 6300, loss: 1.303692102432251\n",
      "iter: 6400, loss: 1.278747320175171\n",
      "iter: 6500, loss: 1.3042871952056885\n",
      "iter: 6600, loss: 1.2973451614379883\n",
      "iter: 6700, loss: 1.349010944366455\n",
      "iter: 6800, loss: 1.2621809244155884\n",
      "iter: 6900, loss: 1.3123011589050293\n",
      "iter: 7000, loss: 1.280623197555542\n",
      "\n",
      "train loss: 1.2289237976074219, val loss: 1.542149305343628\n",
      "\n",
      "avg L values:\n",
      "7.409663696406178\n",
      "6.705187448447855\n",
      "iter: 7100, loss: 1.310913324356079\n",
      "iter: 7200, loss: 1.2372405529022217\n",
      "iter: 7300, loss: 1.2216250896453857\n",
      "iter: 7400, loss: 1.2762460708618164\n",
      "iter: 7500, loss: 1.295946717262268\n",
      "iter: 7600, loss: 1.240801215171814\n",
      "iter: 7700, loss: 1.2714474201202393\n",
      "iter: 7800, loss: 1.2612407207489014\n",
      "iter: 7900, loss: 1.256876826286316\n",
      "iter: 8000, loss: 1.2586896419525146\n",
      "\n",
      "train loss: 1.220510482788086, val loss: 1.5302047729492188\n",
      "\n",
      "avg L values:\n",
      "7.421498364544861\n",
      "6.681189609083952\n",
      "iter: 8100, loss: 1.2303041219711304\n",
      "iter: 8200, loss: 1.200087308883667\n",
      "iter: 8300, loss: 1.2001041173934937\n",
      "iter: 8400, loss: 1.2317568063735962\n",
      "iter: 8500, loss: 1.2077844142913818\n",
      "iter: 8600, loss: 1.249001383781433\n",
      "iter: 8700, loss: 1.2582148313522339\n",
      "iter: 8800, loss: 1.2205291986465454\n",
      "iter: 8900, loss: 1.2219749689102173\n",
      "iter: 9000, loss: 1.2243901491165161\n",
      "\n",
      "train loss: 1.1636625528335571, val loss: 1.5053249597549438\n",
      "\n",
      "avg L values:\n",
      "7.4883565685879585\n",
      "6.6762600789502775\n",
      "iter: 9100, loss: 1.2992961406707764\n",
      "iter: 9200, loss: 1.1727224588394165\n",
      "iter: 9300, loss: 1.181694507598877\n",
      "iter: 9400, loss: 1.258802890777588\n",
      "iter: 9500, loss: 1.1935237646102905\n",
      "iter: 9600, loss: 1.1764837503433228\n",
      "iter: 9700, loss: 1.2648409605026245\n",
      "iter: 9800, loss: 1.1783515214920044\n",
      "iter: 9900, loss: 1.2420889139175415\n",
      "iter: 10000, loss: 1.2292015552520752\n",
      "\n",
      "train loss: 1.1544859409332275, val loss: 1.4992311000823975\n",
      "\n",
      "avg L values:\n",
      "7.524084177472295\n",
      "6.672793001278366\n"
     ]
    }
   ],
   "source": [
    "for i in range(10001):\n",
    "    loss = iter()\n",
    "    lossi.append(loss.item())\n",
    "    if i % 100 == 0:\n",
    "        print(f\"iter: {i}, loss: {loss.item()}\")\n",
    "    if i % 1000 == 0:\n",
    "        print()\n",
    "        losses = estimate_loss()\n",
    "        print(f\"train loss: {losses['train']}, val loss: {losses['val']}\")\n",
    "        print()\n",
    "\n",
    "        train_losses.append(losses['train'])\n",
    "        test_losses.append(losses['val'])\n",
    "\n",
    "        print(\"avg L values:\")\n",
    "        for layer in model.blocks:\n",
    "            print(layer.avg_loop)\n",
    "\n",
    "        # print(\"L values:\")\n",
    "        # for layer in model.blocks:\n",
    "        #     print(layer.L.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]], device='cuda:0')\n",
      "\n",
      "\n",
      "HASTINGS:\n",
      "We are thing withdraw to going; and in these joyfully\n",
      "Did clip to his lady. A most command with\n",
      "such fair death: if ever do not but I were curse shall be put a little\n",
      "must be twixtued by these profits of it.\n",
      "3 KING RICHARD II:\n",
      "Fear, please your \n"
     ]
    }
   ],
   "source": [
    "def generate(max_new=256):\n",
    "    model.eval()\n",
    "    idx = torch.tensor(encode(\"\\n\"), dtype=torch.long, device=device).unsqueeze(0)\n",
    "    print(idx)\n",
    "    for _ in range(max_new):\n",
    "        idx_cond = idx[:, -block_size:]\n",
    "        logits, loss = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    # decode and print\n",
    "    out = idx.squeeze().tolist()\n",
    "    out = decode(out)\n",
    "\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "print(generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f319c25aa40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABG0ElEQVR4nO3deXycZb3///fMZGayTSZJs0zSJG1pk3Rna9G2iAiVHsDagiIiCohylNMqyPGcY/GrbAeqIpsIxYrIUawI/Cwge9kKZS1LoWu6L7TN1iWTdZLM3L8/7plp0iZtkmZyTyav5+Mxj2SuuWfmkxGYt9f9ua7bZhiGIQAAAIvYrS4AAAAMbYQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAx/Twww/LZrNp+/btVpcCIAERRgAAgKUIIwAAwFKEEQAAYCnCCIA+uf/++zVhwgS53W4VFhZq3rx5OnjwYKdjNm3apK997Wvy+XxKTk5WUVGRvvnNb6quri56zLJly3T66acrMzNT6enpKi8v1/XXX9/pdQKBgG644QaNGTNGbrdbxcXF+u///m8FAoFOx/XktQDEnySrCwAw+Nx444266aabNHPmTF199dWqqKjQokWLtHLlSr311ltyOp1qbW3VrFmzFAgE9KMf/Ug+n0+7d+/WM888o4MHD8rr9Wrt2rX6yle+osmTJ+vmm2+W2+3W5s2b9dZbb0XfKxQK6atf/apWrFihf//3f9e4ceO0evVq3XXXXdq4caOefPJJSerRawGIUwYAHMOf//xnQ5Kxbds2o7q62nC5XMY555xjBIPB6DG///3vDUnGQw89ZBiGYXz88ceGJOPxxx/v9nXvuusuQ5JRU1PT7TF//etfDbvdbrz55pudxh944AFDkvHWW2/1+LUAxCdO0wDolZdfflmtra269tprZbcf+k/IVVddpYyMDD377LOSJK/XK0l68cUX1dTU1OVrZWZmSpKeeuophUKhLo95/PHHNW7cOI0dO1a1tbXR21lnnSVJeu2113r8WgDiE2EEQK/s2LFDklReXt5p3OVy6YQTTog+PmrUKF133XV68MEHlZOTo1mzZum+++7r1C9y8cUXa8aMGfr+97+v/Px8ffOb39Rjjz3WKUxs2rRJa9euVW5ubqdbWVmZJKm6urrHrwUgPtEzAiBm7rjjDl1xxRV66qmn9NJLL+nHP/6xFi5cqHfffVdFRUVKSUnRG2+8oddee03PPvusXnjhBf3jH//QWWedpZdeekkOh0OhUEiTJk3SnXfe2eV7FBcXS1KPXgtAnLL6PBGA+NexZ2TJkiWGJOO5557rdEwgEDC8Xq/xta99rdvXeeuttwxJxs9//vNuj7n11lsNScayZcsMwzCM8847zxg+fLgRCoV6XffhrwUgPnGaBkCvzJw5Uy6XS7/73e9kGEZ0/E9/+pPq6up0/vnnS5L8fr/a29s7PXfSpEmy2+3RJbn79+8/4vVPOukkSYoe841vfEO7d+/WH//4xyOObW5uVmNjY49fC0B84jQNgF7Jzc3VggULdNNNN+nf/u3f9NWvflUVFRW6//77NXXqVH3729+WJL366quaP3++LrroIpWVlam9vV1//etf5XA49LWvfU2SdPPNN+uNN97Q+eefrxEjRqi6ulr333+/ioqKdPrpp0uSvvOd7+ixxx7TD3/4Q7322muaMWOGgsGgNmzYoMcee0wvvviipkyZ0qPXAhCnrJ6aARD/Op6mifj9739vjB071nA6nUZ+fr5x9dVXGwcOHIg+vnXrVuPKK680Ro8ebSQnJxvZ2dnGl770JePll1+OHvPKK68Yc+bMMQoLCw2Xy2UUFhYal1xyibFx48ZO79/a2mr8+te/NiZMmGC43W4jKyvLOPXUU42bbrrJqKur69VrAYg/NsPoMM8KAAAwwOgZAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACw1KDY9CwUCmnPnj3yeDyy2WxWlwMAAHrAMAzV19ersLCw01W+DzcowsiePXuiF8MCAACDy65du1RUVNTt44MijHg8HknmH5ORkWFxNQAAoCf8fr+Ki4uj3+PdGRRhJHJqJiMjgzACAMAgc6wWCxpYAQCApQgjAADAUoQRAABgqUHRMwIAQCwYhqH29nYFg0GrSxmUHA6HkpKSjnvbDcIIAGBIam1t1d69e9XU1GR1KYNaamqqCgoK5HK5+vwahBEAwJATCoW0bds2ORwOFRYWyuVysalmLxmGodbWVtXU1Gjbtm0qLS096sZmR0MYAQAMOa2trQqFQiouLlZqaqrV5QxaKSkpcjqd2rFjh1pbW5WcnNyn16GBFQAwZPX1/8njkP74DPlfAQAAWIowAgAALEUYAQBgiBo5cqTuvvtuq8uggRUAgMHkzDPP1EknndQvIWLlypVKS0s7/qKO09CeGXn/j9LSH0oHdlhdCQAA/SKykVtP5ObmxsVqoqEdRlYtkT75u7TnY6srAQBYzDAMNbW2W3IzDKNHNV5xxRVavny57rnnHtlsNtlsNj388MOy2Wx6/vnndeqpp8rtdmvFihXasmWL5syZo/z8fKWnp2vq1Kl6+eWXO73e4adpbDabHnzwQV1wwQVKTU1VaWmpnn766f78mLs0tE/T+CZKez6SqtZIE+ZaXQ0AwELNbUGN/+WLlrz3uptnKdV17K/ke+65Rxs3btTEiRN18803S5LWrl0rSfrZz36m3/72tzrhhBOUlZWlXbt26bzzztOtt94qt9utv/zlL5o9e7YqKipUUlLS7XvcdNNN+s1vfqPbb79d9957ry699FLt2LFD2dnZ/fPHdmFIz4wE8yaYP/d8anElAAAcm9frlcvlUmpqqnw+n3w+nxwOhyTp5ptv1pe//GWNHj1a2dnZOvHEE/WDH/xAEydOVGlpqW655RaNHj36mDMdV1xxhS655BKNGTNGt912mxoaGvT+++/H9O8a0jMj1y0P6h5J7Xs+lcPqYgAAlkpxOrTu5lmWvffxmjJlSqf7DQ0NuvHGG/Xss89q7969am9vV3Nzs3bu3HnU15k8eXL097S0NGVkZKi6uvq46zuaIR1GQnnjpR2Su2mv1LRfSo3dFBQAIL7ZbLYenSqJV4evivnpT3+qZcuW6be//a3GjBmjlJQUff3rX1dra+tRX8fpdHa6b7PZFAqF+r3ejob0aZqSwgLtDOWad6rWWlsMAAA94HK5FAwGj3ncW2+9pSuuuEIXXHCBJk2aJJ/Pp+3bt8e+wD4Y0mGkLN+j9cYI807VGmuLAQCgB0aOHKn33ntP27dvV21tbbezFqWlpfrnP/+pVatW6ZNPPtG3vvWtmM9w9NWQDiNjfRlab5gdxUblaourAQDg2H7605/K4XBo/Pjxys3N7bYH5M4771RWVpamT5+u2bNna9asWTrllFMGuNqeGbwnx/rBqJw0VRgjJUltuz+Ry9pyAAA4prKyMr3zzjudxq644oojjhs5cqReffXVTmPz5s3rdP/w0zZd7Xdy8ODBPtXZG0N6ZsSVZFdT9jhJUtK+CinYZnFFAAAMPUM6jEhSZsFo+Y0U2UNtUu0mq8sBAGDIGfJhpKzAqw3hvhGaWAEAGHhDPoyU53u0PhQOIzSxAgAw4AgjvkPLe0OEEQAABtyQDyPDM1O03TFKkhTaSxgBAGCgDfkwYrfbFMobp6BhU1JzrVRfZXVJAAAMKUM+jEjSCQW52mYUmHeqmB0BAGAgEUYU6RuJNLGyogYAgIFEGFFkRU34GjU0sQIAEtjIkSN19913W11GJ4QRmTMj68IzI6yoAQBgYBFGJA1Ld6sqZYwkybZvs9TWYnFFAAAMHYSRsGzfCO0zPLIZQalmvdXlAAAGmmFIrY3W3Lq4QF1XFi9erMLCQoVCoU7jc+bM0ZVXXqktW7Zozpw5ys/PV3p6uqZOnaqXX345Fp9WvxrSV+3tqMyXofU7S3S6Y63ZxFp4stUlAQAGUluTdFuhNe99/R7JlXbMwy666CL96Ec/0muvvaazzz5bkrR//3698MILeu6559TQ0KDzzjtPt956q9xut/7yl79o9uzZqqioUElJSaz/ij5jZiRsbIedWLlGDQAgHmVlZencc8/VkiVLomNPPPGEcnJy9KUvfUknnniifvCDH2jixIkqLS3VLbfcotGjR+vpp5+2sOpjY2YkrCzfo79yjRoAGLqcqeYMhVXv3UOXXnqprrrqKt1///1yu93629/+pm9+85uy2+1qaGjQjTfeqGeffVZ79+5Ve3u7mpubtXPnzhgWf/wII2Fl+Z2vUWM3DMlms7gqAMCAsdl6dKrEarNnz5ZhGHr22Wc1depUvfnmm7rrrrskST/96U+1bNky/fa3v9WYMWOUkpKir3/962ptbbW46qMjjISluZMUyByj1iaHXAG/VLdLyozf82sAgKEpOTlZF154of72t79p8+bNKi8v1ymnnCJJeuutt3TFFVfoggsukCQ1NDRo+/btFlbbM/SMdHCCL1ubjSLzDjuxAgDi1KWXXqpnn31WDz30kC699NLoeGlpqf75z39q1apV+uSTT/Stb33riJU38Ygw0sHYjtvC08QKAIhTZ511lrKzs1VRUaFvfetb0fE777xTWVlZmj59umbPnq1Zs2ZFZ03iGadpOijzefRJqERfc0iq/NTqcgAA6JLdbteePUc2244cOVKvvvpqp7F58+Z1uh+Pp22YGemg4/Jeg9M0AAAMCMJIB6Ny0rTZZoYR24FtUqDe4ooAAEh8hJEOnA67snMLtdfINgeq1llbEAAAQwBh5DBl+R6tj2x+VsXmZwAAxBph5DDlHVfUsBMrACQ0o4cXqEP3+uMzJIwcZqzPo/Wh8DVqaGIFgITkdDolSU1NTRZXMvhFPsPIZ9oXvVrau2jRIi1atCi6LGjChAn65S9/qXPPPbfL4x9++GF997vf7TTmdrvV0tLSt2oHgLktvDkzYlSvky0UlOwOi6sCAPQnh8OhzMxMVVdXS5JSU1Nl4xIgvWIYhpqamlRdXa3MzEw5HH3/ruxVGCkqKtKvfvUrlZaWyjAM/d///Z/mzJmjjz/+WBMmTOjyORkZGaqoqIjej/f/sYuyUlTtLFKz4VJKW5O0f5uUM8bqsgAA/czn80lSNJCgbzIzM6OfZV/1KozMnj270/1bb71VixYt0rvvvtttGLHZbMdd5ECy2Wwa4/OqorJYJ9m2mE2shBEASDg2m00FBQXKy8tTW1ub1eUMSk6n87hmRCL6vANrMBjU448/rsbGRk2bNq3b4xoaGjRixAiFQiGdcsopuu2227oNLhGBQECBQCB63+/397XMPhnr82jdnhKdZN9iNrFOuGBA3x8AMHAcDke/fKGi73rdwLp69Wqlp6fL7Xbrhz/8oZYuXarx48d3eWx5ebkeeughPfXUU3rkkUcUCoU0ffp0ffbZZ0d9j4ULF8rr9UZvxcXFvS3zuJh9IzSxAgAwEGxGL9fktLa2aufOnaqrq9MTTzyhBx98UMuXL+82kHTU1tamcePG6ZJLLtEtt9zS7XFdzYwUFxerrq5OGRkZvSm3T97eUqs7H/w/PeG+WcoYLl3H5mcAAPSW3++X1+s95vd3r0/TuFwujRlj9lCceuqpWrlype655x794Q9/OOZznU6nTj75ZG3evPmox7ndbrnd7t6W1m/K8z3aENlrxL9batovpWZbVg8AAInsuPcZCYVCnWYxjiYYDGr16tUqKCg43reNqWHpbiWnZ2lHKM8cqOJUDQAAsdKrmZEFCxbo3HPPVUlJierr67VkyRK9/vrrevHFFyVJl112mYYPH66FCxdKkm6++WZ9/vOf15gxY3Tw4EHdfvvt2rFjh77//e/3/1/Sz8b6PFq/Y4RGqNrsGxl1htUlAQCQkHoVRqqrq3XZZZdp79698nq9mjx5sl588UV9+ctfliTt3LlTdvuhyZYDBw7oqquuUmVlpbKysnTqqafq7bff7lF/idXK8j1av61E/+ZYybbwAADEUK8bWK3Q0waY/vTYyl16eemftNh1l+SbJP1wxYC8LwAAiaKn399cm6YbZT6P1kWW99ZUSEE2xAEAIBYII90oy0/XZ0au/EaKFGyVajdaXRIAAAmJMNKNVFeSSrLT2PwMAIAYI4wcRbnPo/Wh8H4jlZ9aWwwAAAmKMHIUY30dtoVnrxEAAGKCMHIUZfkdZ0bWSPG/8AgAgEGHMHIUY30eVRjFCho2qalWaqiyuiQAABIOYeQoRuakKeRwa6tRaA7QxAoAQL8jjByF02HX6Nx0rTdoYgUAIFYII8dgrqihiRUAgFghjBxDuc/TYWaEMAIAQH8jjBxDeb5HayMzI/s2SW3N1hYEAECCIYwcQ7nPoxplap+RIRkhqXq91SUBAJBQCCPHMDwzRelup9ZF9huhbwQAgH5FGDkGm82msvz0DteoWW1tQQAAJBjCSA+U+zI678QKAAD6DWGkB8o7zoxUrWVbeAAA+hFhpAfKfRnaYhSqVUlSoE46uNPqkgAASBiEkR4o93nUpiRtCg03B2hiBQCg3xBGeiA7zaVcj5smVgAAYoAw0kPl+Z4OTayEEQAA+gthpIfKfR6tM7hGDQAA/Y0w0kPmBfPCMyMHtkstfkvrAQAgURBGeqg836OD8qhSw8yB6nXWFgQAQIIgjPRQaX66bDZpbZC+EQAA+hNhpIdSXUkqyU7VeoMwAgBAfyKM9IK5ooYmVgAA+hNhpBc6r6hZJ4WC1hYEAEACIIz0QrnPox1Gvlrkltqbpf1brS4JAIBBjzDSC2N9HoVkV4VRbA7QNwIAwHEjjPTCiGFpcjnsrKgBAKAfEUZ6wemwa3ReOjuxAgDQjwgjvVSen97hGjWEEQAAjhdhpJfKfRnaENlrpH6P1LTf2oIAABjkCCO9VO5LV6NStNvuMwfoGwEA4LgQRnqp3JchSVrdThMrAAD9gTDSS4XeZHncSVoXWVFDEysAAMeFMNJLNptNZT5Ph2vUEEYAADgehJE+KPd5tC5yjZqaDVJ7q7UFAQAwiBFG+qA836PdylGjPV0KtUm1G60uCQCAQYsw0gflPo8kmzaKJlYAAI4XYaQPyvM9kqRVreFr1NDECgBAnxFG+iArzaU8j7tDEyszIwAA9BVhpI86NbFWrZEMw9qCAAAYpAgjfVSe79Emo0ghOaSmfVJ9pdUlAQAwKBFG+qjM51FALu1JGm4O0DcCAECfEEb6aKzPbGJdE9mJtfJTC6sBAGDwIoz0UWmeRzabtKq1yBxgJ1YAAPqEMNJHKS6HRmSnar3RoYkVAAD0GmHkOHRaUbNvs9TWbG1BAAAMQoSR41Ce71GNMlXvyJKMkFS9zuqSAAAYdAgjx6HclyFJ2mwfaQ6w+RkAAL1GGDkO5b50SdLHNLECANBnvQojixYt0uTJk5WRkaGMjAxNmzZNzz///FGf8/jjj2vs2LFKTk7WpEmT9Nxzzx1XwfFk5LA0uZLs+rSNa9QAANBXvQojRUVF+tWvfqUPP/xQH3zwgc466yzNmTNHa9eu7fL4t99+W5dccom+973v6eOPP9bcuXM1d+5crVmTGF/aSQ67xuSma110Rc1atoUHAKCXbIZxfN+e2dnZuv322/W9733viMcuvvhiNTY26plnnomOff7zn9dJJ52kBx54oNvXDAQCCgQC0ft+v1/FxcWqq6tTRkbG8ZTb737yj1X618c7VJHyPTmMNumaT6SskVaXBQCA5fx+v7xe7zG/v/vcMxIMBvXoo4+qsbFR06ZN6/KYd955RzNnzuw0NmvWLL3zzjtHfe2FCxfK6/VGb8XFxX0tM+bKfR61K0l7XCPNAZpYAQDolV6HkdWrVys9PV1ut1s//OEPtXTpUo0fP77LYysrK5Wfn99pLD8/X5WVR7+o3IIFC1RXVxe97dq1q7dlDpjyfHNb+HWhyLbwiXEKCgCAgZLU2yeUl5dr1apVqqur0xNPPKHLL79cy5cv7zaQ9IXb7Zbb7e6314ul8vA1alY2F2pWkmhiBQCgl3odRlwul8aMGSNJOvXUU7Vy5Urdc889+sMf/nDEsT6fT1VVVZ3Gqqqq5PP5+lhu/CnwJsuTnKQ1reEmVk7TAADQK8e9z0goFOrUbNrRtGnT9Morr3QaW7ZsWbc9JoORzWZTeb7n0GmagzukFr+1RQEAMIj0amZkwYIFOvfcc1VSUqL6+notWbJEr7/+ul588UVJ0mWXXabhw4dr4cKFkqRrrrlGX/ziF3XHHXfo/PPP16OPPqoPPvhAixcv7v+/xEJlPo8+2JEuvytfGa1V5hLfEYkTuAAAiKVezYxUV1frsssuU3l5uc4++2ytXLlSL774or785S9Lknbu3Km9e/dGj58+fbqWLFmixYsX68QTT9QTTzyhJ598UhMnTuzfv8JiY8N9I1sdo8wBTtUAANBjvZoZ+dOf/nTUx19//fUjxi666CJddNFFvSpqsImsqFnVWqSTJKmKMAIAQE9xbZp+EFlR817zcHOA5b0AAPQYYaQfZKa6lJ/h1noj3MRavV4KBa0tCgCAQYIw0k/K8j3aYeSrzZEitTdL+7ZYXRIAAIMCYaSfjPV5ZMiuyuQTzIHKT60tCACAQYIw0k/Kwk2sG6JX8KVvBACAniCM9JOxPvNqhCubC80BmlgBAOgRwkg/GZOXLptN+qClyBxgZgQAgB4hjPSTFJdDI4elaYNRIkM2qX6v1FhrdVkAAMQ9wkg/Ks/3qEnJ8qeEZ0fYiRUAgGMijPSjsvDmZzuc4RU1nKoBAOCYCCP9KHKNmtXtxeYATawAABwTYaQfRZb3rqgPr6hhZgQAgGMijPSjkcNS5Uqy65O2cM9ITYXU3mptUQAAxDnCSD9Kctg1JjddezRMbc4MKdQm1WywuiwAAOIaYaSfmX0jNlWljjEHOFUDAMBREUb6WXm4iXWTbaQ5QBMrAABHRRjpZ5HlvR9Gd2JlrxEAAI6GMNLPIst736j3mQOVayTDsLAiAADiG2Gkn/kykuVJTlJFsFCGzSE17ze3hgcAAF0ijPQzm82msT6PAnKpPn2UOci28AAAdIswEgORzc92uUabA4QRAAC6RRiJgUjfyNpQiTnA8l4AALpFGImByMzIOw3hbeFZ3gsAQLcIIzEw1pchSXozsqJm32aptdHCigAAiF+EkRjwpjrly0hWrbxqS8mRZEjV660uCwCAuEQYiZHI5me1aWXmAE2sAAB0iTASI5Em1i32keYATawAAHSJMBIjkSbWj1uLzQGaWAEA6BJhJEYiMyOv1+WbA1VrpVDIwooAAIhPhJEYGZOXLrtNWtWcK8PhllrrpYPbrS4LAIC4QxiJkWSnQyOHpSkohxq8Y8xBTtUAAHAEwkgMRfpG9rjDYYQmVgAAjkAYiaHycN/IemOEOcDMCAAARyCMxFCkifW95vC28FXsNQIAwOEIIzEU2fjslf055sDBnVLzQesKAgAgDhFGYmjksDS5kuyqbktVu2e4OVi11tqiAACIM4SRGHLYbSrNS5ck7U8PbwtPEysAAJ0QRmIs0sS6PekEc4Br1AAA0AlhJMbKw8t7P2kLbwvPzAgAAJ0QRmIsMjPyZoPPHKheLwXbLawIAID4QhiJsbG+DEnS2/s9MlzpUnuLtG+zxVUBABA/CCMxlp/hVkZyktpDNjVnlZuDnKoBACCKMBJjNpstOjtSmRK5Rg1NrAAARBBGBkCZz1zeu1EjzQFmRgAAiCKMDIDy8MzIypbwtvBcowYAgCjCyACILO99/UCeJJvUUCk11FhbFAAAcYIwMgAiYWRLnaFg1ihzkIvmAQAgiTAyILypTvkykiVJdRnhFTWcqgEAQBJhZMBENj/b6RptDtDECgCAJMLIgBkbDiNrgiXmADMjAABIIowMmLJw38jbDQXmQG2F1B6wsCIAAOIDYWSARE7TvF3jlpGcKYXapZoN1hYFAEAc6FUYWbhwoaZOnSqPx6O8vDzNnTtXFRUVR33Oww8/LJvN1umWnJx8XEUPRmPy0mW3SQeb29WWM94c5FQNAAC9CyPLly/XvHnz9O6772rZsmVqa2vTOeeco8bGxqM+LyMjQ3v37o3eduzYcVxFD0bJTodG5qRJkqrTysxBmlgBAFBSbw5+4YUXOt1/+OGHlZeXpw8//FBnnHFGt8+z2Wzy+Xx9qzCBlOd7tLWmUZvto1QkcY0aAAB0nD0jdXV1kqTs7OyjHtfQ0KARI0aouLhYc+bM0dq1a496fCAQkN/v73RLBJG+kY8Cw82BqjWSYVhYEQAA1utzGAmFQrr22ms1Y8YMTZw4sdvjysvL9dBDD+mpp57SI488olAopOnTp+uzzz7r9jkLFy6U1+uN3oqLi/taZlyJ7MT65sEcyZ4kNR+Q/LstrgoAAGvZDKNv/9f86quv1vPPP68VK1aoqKiox89ra2vTuHHjdMkll+iWW27p8phAIKBA4NCyV7/fr+LiYtXV1SkjI6Mv5caFrTUNOuuO5Up22rW+4GbZqtdJl/xDKv83q0sDAKDf+f1+eb3eY35/92lmZP78+XrmmWf02muv9SqISJLT6dTJJ5+szZs3d3uM2+1WRkZGp1siGDEsTe4ku1raQmrMHGsOco0aAMAQ16swYhiG5s+fr6VLl+rVV1/VqFGjev2GwWBQq1evVkFBQa+fO9g57DaV5qdLkj5zjzEHWd4LABjiehVG5s2bp0ceeURLliyRx+NRZWWlKisr1dzcHD3msssu04IFC6L3b775Zr300kvaunWrPvroI33729/Wjh079P3vf7///opBpDzfnOVZHwpvC8/yXgDAENerpb2LFi2SJJ155pmdxv/85z/riiuukCTt3LlTdvuhjHPgwAFdddVVqqysVFZWlk499VS9/fbbGj9+/PFVPkiV+8yZkXebCnWBJO3bIrU2Sq40S+sCAMAqfW5gHUg9bYAZDJZvrNHlD72v0blpesX4d6mhSvrey1LxVKtLAwCgX8W0gRV9F1neu31fk4J5E8xBmlgBAEMYYWSA5We45U1xKhgytN9Tbg7SxAoAGMIIIwPMZrNFZ0e2OcKrkWhiBQAMYYQRC0S2hV/VFt5ZtmqtFApZWBEAANYhjFggEkbercuSHG6ptUE6sM3iqgAAsAZhxAKRMLKhqknKG2cOcqoGADBEEUYsUBbuGdlT16LWnPCKGppYAQBDFGHEAt4Upwq8yZKkytTwtvDMjAAAhijCiEWip2qMEeYAMyMAgCGKMGKRyPLelU2F5kDdTqn5gIUVAQBgDcKIRSIzI5/sk+SNXDRvrXUFAQBgEcKIRSJhpKKyXoaPJlYAwNBFGLHI6Nx0Oew21TW3qTErfAVjrlEDABiCCCMWSXY6NHJYqiRph/MEc5CZEQDAEEQYsVDkVM3qyLbw1eulYLuFFQEAMPAIIxYqz8+QJH1QlyG50qVgQNq3yeKqAAAYWIQRC5X70iVJFdWNUj5NrACAoYkwYqFynzkzsrGqXqH8SeYgTawAgCGGMGKhkuxUJTvtCrSHtC+91BxkZgQAMMQQRizksNtUmmc2sW62jTQHK5kZAQAMLYQRi0VW1HzYUiDJJjVWSw3V1hYFAMAAIoxYLHKNmnW17dKw0eYgsyMAgCGEMGKx6NV7K+ul/InmYBV9IwCAoYMwYrFIGNle26i2vHAYoYkVADCEEEYsludxKzPVqZAh7XaHT9MwMwIAGEIIIxaz2WwqC/eNrA+VmIM1FVJbi4VVAQAwcAgjcWBs+FTNqoOpUkqWZASlmg0WVwUAwMAgjMSByMzIhqoGmlgBAEMOYSQORGZGNlbVS77J5iBNrACAIYIwEgfKwmFkb12LmrLHmYPMjAAAhgjCSBzISHaq0JssSdrqGGUOVn4qGYaFVQEAMDAII3Eist/IJ4F8yZ4ktdRJdZ9ZXBUAALFHGIkTkVM1G6oDUk65OcipGgDAEEAYiRORJtaKynrJN8kcpIkVADAEEEbiRGR5b0VVvYz8CeZgFRfMAwAkPsJInBiTly6H3aa65jYd8IRP03D1XgDAEEAYiRPuJIdG5aRJktYb4W3h92+TAg0WVgUAQOwRRuJIefhUzdo6l5Tuk2RI1eusLQoAgBgjjMSRyPLeDZX1ki+8LTynagAACY4wEkciTazmtvDhFTUs7wUAJDjCSByJLO/dVNWgUF5kZoQwAgBIbISROFKcnapkp12B9pB2u0ebg1VrpVDI2sIAAIghwkgccdht0VM1a1typKRkqa1ROrDN4soAAIgdwkiciYSRDTXNUl74Cr40sQIAEhhhJM50uS08TawAgARGGIkz5R3DSD7XqAEAJD7CSJyJbHy2fV+jAjnjzUFO0wAAEhhhJM7ketzKSnUqZEhb7CPMQf9nUtN+awsDACBGCCNxxmY7tKJm/X6blBm+Tk3VWgurAgAgdggjcSjaxFpVL/kmm4M0sQIAEhRhJA6VdWpiZSdWAEBiI4zEoc7LeyNh5FMLKwIAIHZ6FUYWLlyoqVOnyuPxKC8vT3PnzlVFRcUxn/f4449r7NixSk5O1qRJk/Tcc8/1ueChoDTcM1Lpb5HfO9YcrNkgBdssrAoAgNjoVRhZvny55s2bp3fffVfLli1TW1ubzjnnHDU2Nnb7nLfffluXXHKJvve97+njjz/W3LlzNXfuXK1Zw2mH7mQkOzU8M0WStKElS3J5pGCrVLvJ4soAAOh/NsMwjL4+uaamRnl5eVq+fLnOOOOMLo+5+OKL1djYqGeeeSY69vnPf14nnXSSHnjggR69j9/vl9frVV1dnTIyMvpa7qBy5cMr9eqGat0yZ4K+s+4H0q53pQv/KE3+htWlAQDQIz39/j6unpG6ujpJUnZ2drfHvPPOO5o5c2ansVmzZumdd97p9jmBQEB+v7/TbaiJLO81V9REdmJl8zMAQOLpcxgJhUK69tprNWPGDE2cOLHb4yorK5Wfn99pLD8/X5WVld0+Z+HChfJ6vdFbcXFxX8sctLpsYmV5LwAgAfU5jMybN09r1qzRo48+2p/1SJIWLFigurq66G3Xrl39/h7xLjozUlkvI7q8l5kRAEDiSerLk+bPn69nnnlGb7zxhoqKio56rM/nU1VVVaexqqoq+Xy+bp/jdrvldrv7UlrCGJ2XJofdJn9LuyqTR6nAZpcaa6T6KsmTf+wXAABgkOjVzIhhGJo/f76WLl2qV199VaNGjTrmc6ZNm6ZXXnml09iyZcs0bdq03lU6xLiTHBqVkyZJqtgXlLJHmw9UMTsCAEgsvQoj8+bN0yOPPKIlS5bI4/GosrJSlZWVam5ujh5z2WWXacGCBdH711xzjV544QXdcccd2rBhg2688UZ98MEHmj9/fv/9FQmqvFPfSKSJlb4RAEBi6VUYWbRokerq6nTmmWeqoKAgevvHP/4RPWbnzp3au3dv9P706dO1ZMkSLV68WCeeeKKeeOIJPfnkk0dteoVpbD5NrACAxNernpGebEny+uuvHzF20UUX6aKLLurNW0EdrlFTVS+dzPJeAEBi4to0cSyyvHdTdYPac8ebg7WbpLYWC6sCAKB/EUbiWHFWqlKcDrW2h7SjzSulZEtGUKpZb3VpAAD0G8JIHLPbbSrLT5ckVVQ10MQKAEhIhJE4V5bfxYoamlgBAAmEMBLnOi3vZSdWAEACIozEuUgY2VjVYXlv5Rqp7xdbBgAgrhBG4lwkjGzf16iWzDGS3SkF6qS6oXe9HgBAYiKMxLncdLey01wKGdKm2lYpt9x84MOHpWC7pbUBANAfCCNxzmbruKKmXhp7vvnAm3dID5wubV1uYXUAABw/wsggMNaXIUmqqPRLX/wf6St3m3uO1KyX/vJV6R/fkQ7ssLZIAAD6iDAyCESX91Y1SHaHNOW70o8/kk77gWSzS+uflu47TXr9V1Jb8zFeDQCA+EIYGQQOLe/1HxpMyZLO+430wxXSyC9I7S3S6wul358mrXuK1TYAgEGDMDIIRHpGqvwBHWxq7fxg/gTp8n9JFz0sZRRJdTulxy4zT99Us208ACD+EUYGAU+yU8MzUySFNz87nM0mTbhAmr/S7ClxuKVtb0iLZkjP/4/UfGCAKwYAoOcII4NEp83PuuNKlb50vTT/fWncbPOieu89IN17qrkUOBQcmGIBAOgFwsggEQkjG7qaGTlc1kjp4kek7zwp5ZRLTfukf10j/fEsaed7Ma0TAIDeIowMEmM7XqOmp0Z/Sbr6LWnWQsmdIe1dJT10jvTPH0j+vbEpFACAXiKMDBKHlvfWy+jNShmHU5r2H9KPPpJO/o4km/Tpo9Lvp0gr7pbaAzGpFwCAniKMDBKjc9OVZLepvqVde+taev8C6bnSnN9LV70iFU2VWhukl2+Q7p8mbXyp/wsGAKCHCCODhCvJrlE5aZLC28L31fBTpStfkuY+IKXlSfu3SEsukv72DWnfln6qFgCAniOMDCLlfekb6YrdLp10ifSjD6XpPzavBLzpRem+z0nLbpACDf1QLQAAPUMYGUTKw30jG483jEQkZ0jn3CL9xzvS6LOlUJv01t1mP8mnj7GLKwBgQBBGBpFeLe/tjZxS6dv/n3TJo+ay4Pq90j+vkh6aJe1Z1b/vBQDAYQgjg0jk6r2baxrUHgz174vbbFL5udJ/vCed/UvJmSrtek9afKa5R0ljbf++HwAAYYSRQaQoK0WpLoda20Pavq8pNm/iTJa+8J/S/A+kSRdJMszdW+89RXrvD1KwPTbvCwAYsggjg4jdblNpuG/kTyu2qqk1hsHAO1z62oPSd5+X8idJLXXS8/8t/eEL5nVvAADoJ4SRQWbuSYWSpL+/v0vn3PWGXttQHds3HDFd+sFy6fw7pZQsqXqd9H+zpcculw7ujO17AwCGBJvRq+08reH3++X1elVXV6eMjAyry7Hcy+uqdMPTa7X7YLMk6bxJPt0we4LyM5Jj+8ZN+6XXbpM++JNkhKSkFOn0n0gzfiw5U2L73gCAQaen39+EkUGqMdCuu1/eqIfe2q5gyFC6O0k/PadM35k2Ug67LbZvXrlGev5/pB0rzPveEmnWreaVgm0xfm8AwKBBGBki1u3x6/qlq7Vq10FJ0uQir267YJImDvfG9o0NQ1q7VHrp/0n+3ebYqC9K5/5ayhsX2/cGAAwKhJEhJBgytOT9nfrNCxtU39Iuu026YvooXXdOmdLdSbF989ZGacVd0lu/k4IByeaQTvt36cyfSSmZsX1vAEBcI4wMQdX1LbrlmfX61yd7JEkF3mTd+NUJmjXBF/s337/NnCXZ8Ix5PzXH3K/k5G9Ldkfs3x8AEHcII0PY8o01+sWTa7Rzv7kXycxx+bppzgQNzxyAJtPNr0gv/Eyq3WjeLzhJOu92qfi02L83ACCuEEaGuJa2oO59dZMWv7FVbUFDqS6HfjKzTN+dMVJJjhiv6A62Se8vll7/lRTwm2OTvmE2uPomSZkjzIv1AQASGmEEkqRNVfW6fulqrdx+QJI0riBDt10wUSeXZMX+zRuqpZdvklY90nnc5ZHyJ0i+iWY4yZ9kNr26UmNfEwBgwBBGEBUKGXr8w11a+PwGHWxqk80mXfq5Ev3XrLHypjhjX8BnH0ofPiRVrpaq10vB1iOPsdml7NGdA4pvouQpYLkwAAxShBEcYV9DQLc+t17//MhcipvrceuXXxmvr0wukG2gvvCDbVLtJqlqjRlOKlebvzfWdH18SrYZTnyTpPyJZkDJKZeSXANTLwCgzwgj6NbbW2r1/5au0dbaRknSGWW5+t85E1UyzMLTJPVVUlU4nFSuMQNK7SbJCB55rN0p5Y41g0n+xENhJTV74OsGAHSLMIKjCrQH9cDrW3Xfa5vVGgzJnWTXj88u1VVfOEGupDhpLm1rNk/rVK05FFAq10iBuq6P9xQeGVCyT2BpMQBYhDCCHtla06D/9+Qavb1lnySpNC9dt104SVNHxuksg2GYF+iLBpTwbMqB7V0f70w1m2Ojp3kmmc2zbs+Alg0AQxFhBD1mGIaeXLVb//vMeu1rNJtLL55SrJ+dO1ZZaYOkN6PFb15RuGMfStU6qb256+OzRoVnUSYdapr1FtMsCwD9iDCCXjvY1Kpfv7BBf39/lyQpO82ln583TheeMnzgGlz7Uygo7d8qVX7a+TRP/Z6uj0/2mrMn0RmU8VJKljm74kwxr1LscBJYAKCHCCPosw+279f1S1drY1WDJGnaCcP0vxdM1OjcdIsr6yeN+8Knd9YcWtVTUyGF2o79XJvjUDhxpnT4PVVyJncx1uG4pOQuHut4TIdjHQOw5BoAYowwguPS2h7Sgyu26nevbFJLW0guh11XnzlaV585WsnOBGwIbW+VaivMgFK52gwrNRul1gbzYoAa4H9N7EnHCDNdBZpkyZkmeXzmLreZJVJaDjM5ACxDGEG/2LW/Sb94ao1erzD3ARmVk6Zb507U9DE5Flc2gAzD3Kitrclc4dPWHP69pcPYYT/bu3qsq+cd9tz+Dj1JKVJmsRlMvOGfHW9peWzNDyBmCCPoN4Zh6LnVlbrpX2tVXR+QJF1w8nD9/Pxxykl3W1xdAuk29Bwt/IR/j4SfQIPk32OuOKrfq2OGG4db8haFw0kkrIw4FFw8PpZGA+gzwgj6nb+lTXe8WKG/vLtDhiF5U5xacO5YfWNKsex2TgXEnfZWyf+ZGUwO7jJ/1oV/Htwp+XdLRujor2F3St7hh2ZSvB1nVorNvV0cSQPz9wAYdAgjiJlVuw7q+n+u1rq95hV5p4zI0m0XTlJZPnt3DCrBtkOzKB1DSsewEmo/+mvYHGZYOTykRH7PGE4zLjCEEUYQU+3BkB5+e7vuXLZRTa1BJdltuuqME/Tjs0qV4mJaPyGEguapnmhA2SUd3NEhvOw69gokm92cPTk8pEROA3mLpCRO9QGJijCCAbHnYLNufHqtXlpXJUkqzk7RzXMm6kvleRZXhpgLhaSGykOngA7uOGyGZZcUDBzjRWxmX4ozxQwuspmrf7r93Rb+3X7k70c8R4eNd/GcTs+3HeP9D39Oh78h+qut81iP7/fXc45Rh91prrpK6nBzpnT4/fBxt9kEneQ279M/hF4ijGBAvbS2Ujc+vVZ76lokSedPLtANXxmvvIxkiyuDZUIh82rMB3dKdTs7965EZlfamqyuEr1hTzLDyRGBppvfexJwIve7C0nOFJanD2KEEQy4xkC77lq2UX9+e7uCIUMed5L+69/KdennRshBgysOZxhS0z4zmARbzftGSJJx2O8h8350vCfHhQ4d26PjQp1f/5jHhQ79DYf+oE4/Dt03jn6/J8cc13M6HB9qCy89D5iXSmgPdL7f1nLkYz3ZDDCWbA5zd+SUrC5umV2PJ2eaj9GvZLmYhZE33nhDt99+uz788EPt3btXS5cu1dy5c7s9/vXXX9eXvvSlI8b37t0rn8/Xo/ckjAwua/fU6fqla/TJroOSpBOLvLrtwkmaUOi1tjAAvRcKhpeOt5g/I7fo/eajPNZylPDT8dgugtGxmqd7wuU5LLRkHiW8dLjPbEy/6en3d6/X5DU2NurEE0/UlVdeqQsvvLDHz6uoqOhUSF4ePQWJakKhV/+8erqWvLdDv3mhQp98VqfZ967QySVZ+kJpjr5QmqsTi7xKcrDZFhD37A7JlWbeBlKw3QwrgXqp5aDUfKCLWxfjLQelljrzNVrrzVvdzt69t8N9lPCSeWR4idzcGWwi2EfHdZrGZrP1eGbkwIEDyszM7NP7MDMyeFX5W3TzM+v07Kd7O417kpM0Y3SOTi/N0RmluSoZlmpRhQASTihoBpJjBZdIeOl4/3hmZGx285SSy2OGOIfT7LOxO8zmYXtSeMwRHu/wePTYDo9HxzrcHB3vOw97bsfjunjvTs/v4r1Tc6Sk/r1Se8xmRvrqpJNOUiAQ0MSJE3XjjTdqxowZ3R4bCAQUCBzqwvf7/QNRImIgPyNZ933rFF1/XrNWbKrRG5tqtWJTreqa2/TC2kq9sLZSkjRiWGp01mTa6GHKSOZcL4A+sjuk1Gzz1huGYV6Pqkfh5bDH25rMXqLI/cHoe8uk4tMseeuYh5GCggI98MADmjJligKBgB588EGdeeaZeu+993TKKad0+ZyFCxfqpptuinVpGEDDM1N08dQSXTy1RMGQoTW76/RmOJx8tOOAduxr0o59O/XIuzvlsNt0cnGmvlCaqy+U5WjycE7pABgANpvk9pi3zJLePbc9cCigtDaaMyyhdrMBONRunnYKdXELtnUx1n7Y84NdHxd9fvDQ+xzz+R2OjT43fJyFS7djfpqmK1/84hdVUlKiv/71r10+3tXMSHFxMadpElRDoF3vbtmnNzfV6M1Ntdpa29jp8YzkJM0YY86afKE0R8XZnNIBgMEg7k7TdHTaaadpxYoV3T7udrvldrMr41CR7k7SzPH5mjk+X5J5peAVm2v15qYardhUK39Lu55fU6nn15indEblpEVP6Xz+hGx5OKUDAIOaJWFk1apVKigosOKtMQgUZ6fqktNKdMlp5imdTz87qDc3meHko50Hta22UdtqG/WXd3YoyW7TKZFVOmW5mjTcy54mADDI9DqMNDQ0aPPmzdH727Zt06pVq5Sdna2SkhItWLBAu3fv1l/+8hdJ0t13361Ro0ZpwoQJamlp0YMPPqhXX31VL730Uv/9FUhYDrtNJ5dk6eSSLP347FLVt7TpnS37ouFk+74mvb99v97fvl93LNsob4pTp4/J0RdKzZU6RVmc0gGAeNfrMPLBBx902sTsuuuukyRdfvnlevjhh7V3717t3HloTXdra6v+8z//U7t371ZqaqomT56sl19+ucuN0IBj8SQ7dc4En86ZYG6Yt3Nfk97cXKM3N9bqrS3mKp1nV+/Vs6vNpcQn5KbpjHCvyedOGKZ0N5e7B4B4w3bwSBjtwZA++awu2gi7atdBBUOH/vFOstt0yogsfbHMDCcTCjmlAwCxxLVpMOTVNUdO6ZjhZOf+zhdly0p1avqYHJ0RboYtzEyxqFIASEyEEeAwO/Y16o1NtXpzY43e2bJP9YHOOy2Ozk3TF0pzdUZZjj43apjSOKUDAMeFMAIcRVswpE92HVqls2rXQXU4oyOnw1ylc1JJpiYUejWhMEOjhqXJzmkdAOgxwgjQC3VNbXpna63e2FSrNzbW6LMDzUcck+pyaFxBhiYURm5eleany51k3a6FABDPCCNAHxmGoR37mvT2ln1au6dOa/f4taHSr5a20BHHJtltKs33dAoo4wo8bMQGACKMAP2qPRjSttpGrd3jjwaUtXv8qmtu6/L4kcNSNT4cTsaHg0qeJ3mAqwYAaxFGgBgzDEO7DzZHg8m6cEjZW9fS5fG5HnenGZQJhRkqyU6VzUYfCoDERBgBLLK/sVXrOs2g1GlrbaO6+jfN407SuMMCypi8dDm5SjGABEAYAeJIU2u71u+tj86erN3jV0VlvVqDR/ahuBx2lfnSNaHAqwnDzaAyriBDqS6WGgMYXAgjQJxrC4a0ubohfIrHnEFZt9ev+pb2I4612cyrFUdmTyIzKdlpLgsqB4CeIYwAg5BhGNq1v7nTKZ61e/yqrg90eXyBN1kTCjM0vtCr8eFlx0VZKfShAIgLhBEggdTUB6LBZN0ev9bt9WtbbWOXx3qSk1Se71G5z6OxPo/KfRkq93nkTWG5MYCBRRgBElxDoF3r9/q1dvehPpRN1fVqC3b9r3SBN1nlvg4hJT9Do/PS2LQNQMwQRoAhqLU9pK21DaqorNeGynpVhG+7Dx65o6wkOew2nZCT1mkWZazPo+GZKWx9D+C4EUYARPlb2rTxsICyodIvfxfNspKU5nKoLDqDciikZNEwC6AXCCMAjsowDFX6Ww4LKPXaUt3Q5ZJjScrzuI+YRRmTl65kJ6d6AByJMAKgT9qCIW2vbYyGlA2V9aqo8mvX/q5P9dht0sictGgfSiSslGSncqoHGOIIIwD6VUOgXRur6juf7qmq1/7G1i6PT3E6VJafHm6azQjPpniUk+4e4MoBWIUwAiDmDMNQTUOg02meisp6bayqV6C961M9OekuM6DkHwooRVkpykp1MZMCJBjCCADLBEOGduxr7Lyqp6pe2/d1fY0eSUqy25ST7lZehlu5kZ+eZOV63MoL33LDN5YjA4MDYQRA3GluDWpTdedVPRVV9arpZofZ7nhTnGZAiQaX5E5hxfw9WRnJSexGC1iop9/fXHkLwIBJcTk0uShTk4syO423BUPa19Cq6voW1dQHVF0fULU/oJqGFlX7zfs14VtrMKS65jbVNbdpU3XDUd/PnWTvMLOS3CGomEEmMjYszaUkrpQMWIYwAsByToddPm+yfN7kox5nGIb8ze2qrm+JBpTq+pZwcAl0+Nkif0u7Au0hfXagWZ8d6HolUITNJg1Lcx9xSigyw2IGF3OMqycD/Y9/qwAMGjabTd5Up7ypTpXme456bEtbMDrLUtNhxiU68xIeq21oVTBkqLYhoNqGgNbvPXoN6e4k5Xrcykp1KiPFKW+KUxnJTmWkJIV/Hrp/6DGnPMlJcjL7AnSJMAIgISU7HSrOTlVxdupRjwuGDO1vbI3OsnQMLdGZl/Bpo+a2oBoC7WoItGtbH2pKdTmUkRwOMJ3CS9JRg403xan05CQ5WG2EBEUYATCkOey2aOPreB29Qb4h0K5qvxlYDja3yd/cJn9Lu+qiv7fJ39we/nno8YaAue1+U2tQTa1BVfpb+lSrx50UnWXpGFSOGWxSnEp3JbF0GnGLMAIAPZTuTlJ6brpOyE3v1fPagyE1BNrlbw4Hl5Yjw0tdh/DS8bG65jY1twUlSfWBdtUHur6e0LHYbOZGdE6HXU6HXS6HTc4ke+f74d+dSYfdd9jlSjrsvsMmV4fn9+w5djnDY67ouC38XPM+sz9DE2EEAGIsyWFXZqpLmal9u9Bga3tI9S2HgkpdV7MwLW2qa+4YZA4dH2gPyTDMmRkp2L9/XD+z29QhuNiVlerUmLx0jclL1+jcQz/T3Hx9JRL2GQGABNfSFpS/pU2BtpBagyG1BUNqbY/8NNQWHmsLhtQaNNTWftj9YCg6Fr0f7NnzA9HfjQ7POXS/PdS3r6BCb7JGdwgokZCSk+5ib5k4wj4jAABJZjNvvF5ZORQy1BYKh5No4DHvt7aHVOVv0ebqBm2uadDm6gZtrWlQbUOr9tS1aE9di97cVNvp9bwp4ZmU3HSNzksL/+7R8KwUTgHFMWZGAACDyoHGVm0Jh5PIz801DfrsQHO3lxtwJ9l1Qm66RuemRWdSxuSla+SwtLgNaomA7eABAENKc2tQ22obo7MoW6rNn9tqG9Ua7PrCjXabVJydqjEd+lFGh4OKN8U5wH9B4iGMAAAgcy+ZXfubojMoWzqc9qlv6X51Uq7HfWgmJTddY/I8Gp2XJl9GMn0pPUQYAQDgKAzDUE194FBAiYaVxqPuBZPuTtLo3LQjGmhHZKdyjaPDEEYAAOij+pY2balpNANKuDdlS3WDduxvUrCbFUBOh00jhqWpMDNFLodd7iRzH5XIfiyupPCtw9Jll6PD2GHHOR228GscOsYZfd1DxyXZbXE7U0MYAQCgnwXag9qxr6nTTIq5yqcxujmdFVyHBRtnkq3b8NIx3HQMQd+dMfKYl0/oLZb2AgDQz9xJDpXle1R22IUaQyFDe+qatbnaXHrccS+XQHvHfV0OLV8OtEeWMAejS5lb283HOh7X8XUir3H45EzkuQr0/W/7yokF/R5GeoowAgDAcbLbbSrKSlVR1sB8mQdDh4WX8MZ0kfDSKdAcEXI6BKAOIafAmzwgtXeFMAIAwCDjsNuU4nIoxZUYe6TQ9gsAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoPiqr2GYUiS/H6/xZUAAICeinxvR77HuzMowkh9fb0kqbi42OJKAABAb9XX18vr9Xb7uM04VlyJA6FQSHv27JHH45HNZuu31/X7/SouLtauXbuUkZHRb6+LzvicBw6f9cDgcx4YfM4DI5afs2EYqq+vV2Fhoez27jtDBsXMiN1uV1FRUcxePyMjg3/QBwCf88Dhsx4YfM4Dg895YMTqcz7ajEgEDawAAMBShBEAAGCpIR1G3G63brjhBrndbqtLSWh8zgOHz3pg8DkPDD7ngREPn/OgaGAFAACJa0jPjAAAAOsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsNSQDiP33XefRo4cqeTkZH3uc5/T+++/b3VJCWXhwoWaOnWqPB6P8vLyNHfuXFVUVFhdVsL71a9+JZvNpmuvvdbqUhLO7t279e1vf1vDhg1TSkqKJk2apA8++MDqshJOMBjUL37xC40aNUopKSkaPXq0brnllmNebA1H98Ybb2j27NkqLCyUzWbTk08+2elxwzD0y1/+UgUFBUpJSdHMmTO1adOmAaltyIaRf/zjH7ruuut0ww036KOPPtKJJ56oWbNmqbq62urSEsby5cs1b948vfvuu1q2bJna2tp0zjnnqLGx0erSEtbKlSv1hz/8QZMnT7a6lIRz4MABzZgxQ06nU88//7zWrVunO+64Q1lZWVaXlnB+/etfa9GiRfr973+v9evX69e//rV+85vf6N5777W6tEGtsbFRJ554ou67774uH//Nb36j3/3ud3rggQf03nvvKS0tTbNmzVJLS0vsizOGqNNOO82YN29e9H4wGDQKCwuNhQsXWlhVYquurjYkGcuXL7e6lIRUX19vlJaWGsuWLTO++MUvGtdcc43VJSWU//mf/zFOP/10q8sYEs4//3zjyiuv7DR24YUXGpdeeqlFFSUeScbSpUuj90OhkOHz+Yzbb789Onbw4EHD7XYbf//732Nez5CcGWltbdWHH36omTNnRsfsdrtmzpypd955x8LKEltdXZ0kKTs72+JKEtO8efN0/vnnd/rnGv3n6aef1pQpU3TRRRcpLy9PJ598sv74xz9aXVZCmj59ul555RVt3LhRkvTJJ59oxYoVOvfccy2uLHFt27ZNlZWVnf774fV69bnPfW5AvhcHxVV7+1ttba2CwaDy8/M7jefn52vDhg0WVZXYQqGQrr32Ws2YMUMTJ060upyE8+ijj+qjjz7SypUrrS4lYW3dulWLFi3Sddddp+uvv14rV67Uj3/8Y7lcLl1++eVWl5dQfvazn8nv92vs2LFyOBwKBoO69dZbdemll1pdWsKqrKyUpC6/FyOPxdKQDCMYePPmzdOaNWu0YsUKq0tJOLt27dI111yjZcuWKTk52epyElYoFNKUKVN02223SZJOPvlkrVmzRg888ABhpJ899thj+tvf/qYlS5ZowoQJWrVqla699loVFhbyWSeoIXmaJicnRw6HQ1VVVZ3Gq6qq5PP5LKoqcc2fP1/PPPOMXnvtNRUVFVldTsL58MMPVV1drVNOOUVJSUlKSkrS8uXL9bvf/U5JSUkKBoNWl5gQCgoKNH78+E5j48aN086dOy2qKHH913/9l372s5/pm9/8piZNmqTvfOc7+slPfqKFCxdaXVrCinz3WfW9OCTDiMvl0qmnnqpXXnklOhYKhfTKK69o2rRpFlaWWAzD0Pz587V06VK9+uqrGjVqlNUlJaSzzz5bq1ev1qpVq6K3KVOm6NJLL9WqVavkcDisLjEhzJgx44il6Rs3btSIESMsqihxNTU1yW7v/PXkcDgUCoUsqijxjRo1Sj6fr9P3ot/v13vvvTcg34tD9jTNddddp8svv1xTpkzRaaedprvvvluNjY367ne/a3VpCWPevHlasmSJnnrqKXk8nuh5R6/Xq5SUFIurSxwej+eIPpy0tDQNGzaM/px+9JOf/ETTp0/Xbbfdpm984xt6//33tXjxYi1evNjq0hLO7Nmzdeutt6qkpEQTJkzQxx9/rDvvvFNXXnml1aUNag0NDdq8eXP0/rZt27Rq1SplZ2erpKRE1157rf73f/9XpaWlGjVqlH7xi1+osLBQc+fOjX1xMV+vE8fuvfdeo6SkxHC5XMZpp51mvPvuu1aXlFAkdXn785//bHVpCY+lvbHxr3/9y5g4caLhdruNsWPHGosXL7a6pITk9/uNa665xigpKTGSk5ONE044wfj5z39uBAIBq0sb1F577bUu/5t8+eWXG4ZhLu/9xS9+YeTn5xtut9s4++yzjYqKigGpzWYYbGkHAACsMyR7RgAAQPwgjAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApf5/LKIFKuKvoKEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('losses')\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='val')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
